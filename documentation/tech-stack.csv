Component,Selected Technology / Model,Role & Justification (Optimized for 12GB VRAM)
LLM Runner,Ollama (full GPU acceleration),"Proven, simple local inference with seamless GGUF support and fast model switching."
Frontend / Hosting,Chainlit (Python-based),"Lightweight, fully customizable local UI: supports chat, multimodal, voice, and easy theming. No branding restrictions. Bound to LAN IP."
Database,PostgreSQL,"Persistent storage for chat history, users, and memory in advanced setups. Scalable and reliable for multi-user scenarios."
Image Generation,FLUX.1 [dev] or FLUX.1 Schnell,"2025 state-of-the-art open-source image model: superior photorealism, prompt adherence, anatomy, and text rendering. Efficient on 12GB VRAM."
Video Generation,Wan 2.1 / Wan 2.2 (1.3B-14B variants),"Best low-VRAM video model in 2025: generates short clips (8-30s) efficiently (~8-12GB VRAM), with strong motion and quality."
Multimodal Analysis,Qwen2.5-VL 7B-32B (quantized),Leading local VLM for image/video/document understanding and summarization; excellent OCR and reasoning. Fits quantized on 12GB.
Framework / Agents,LangChain,"Robust tool integration, agents, and RAG orchestration."
Memory / RAG,ChromaDB + Sentence Transformers (all-MiniLM-L6),Efficient long-term user memory and retrieval for personalization.
Fine-Tuning,Unsloth (LoRA),Fastest GPU-based LoRA fine-tuning for personalizing the core LLM on your dataset.
Voice / TTS,Piper TTS,High-quality local TTS with customizable voices for your persona.
Network Access,OpenVPN (using your router-exported .ovpn config),"Secure, trusted device access via your existing home VPN setup."